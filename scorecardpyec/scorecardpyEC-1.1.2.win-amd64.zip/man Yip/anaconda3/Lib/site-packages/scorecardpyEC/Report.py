# -*- coding: utf-8 -*-
"""
Created on Fri Jan  7 17:13:01 2022

@author: man Yip
"""
import numpy as np
import warnings
warnings.filterwarnings(action ='ignore',category = DeprecationWarning)
import pandas as pd
import statsmodels.api as sm
import scorecardpy as sc
import sys
sys.path.append('./')
from Bin import ECBin
from Tool import vif,KS,AUC

def lift(df,score_col='score',y_col='y',weight_col=None,n=10,cuts=None):
    if weight_col is None:
        df['weight']=1
    else:
        df['weight']=df[weight_col]
    def _get_cuts(df):
        df = df.sort_values(score_col)
        df['w1']=df.weight.cumsum()/df.weight.sum()
        df = df.drop_duplicates([score_col],keep='last')
        if df.shape[0] < n:
            m = df.shape[0]
        else:
            m=n
        step=100/m*0.01
        step = np.round(step,3)
        point=step
        cuts=[-np.inf]
        
        while(point<(1)):
            tmp1 = df.loc[df.w1<=point]
            if tmp1.shape[0]==0:
                tmp1 = df.iloc[0]
            else:
                tmp1 = tmp1.iloc[-1]
            tmp2 = df.loc[df.w1>point].iloc[0]      
            if (np.round(point-tmp1['w1'],3)<=np.round(tmp2['w1']-point,3)) and (cuts[-1] < tmp1.score):
                tmp= tmp1
            else:
                tmp= tmp2
            if tmp['w1']<=0.98:
                cuts.append(tmp.score)
            point = tmp['w1']+step
        cuts.append(np.inf)
        return cuts
    if not cuts:
        cuts=_get_cuts(df)
    df['pred_label'] = pd.cut(df[score_col],cuts,retbins=False,duplicates='drop',include_lowest=True,right=True)  
    
    def _weight_info(row):
        d={}
        d['TOTAL']=np.around(row['weight'].sum(),0)
        d['BAD']=np.around((row['weight']*row[y_col]).sum(),0)
        d['GOOD']=np.around(row.loc[row[y_col]==0,'weight'].sum(),0)
        return pd.Series(d)
    
    df = df.groupby('pred_label').apply(_weight_info)
    df.index.name='INTEVAL'
    df['CUMULATIVE']=df['TOTAL'].cumsum()/df['TOTAL'].sum()
    df['GOOD_CUM_RATE']=df['GOOD'].cumsum()/df['GOOD'].sum()
    df['BAD_CUM_RATE']=df['BAD'].cumsum()/df['BAD'].sum()
    df['BAD_RATE1']=df['BAD']/df['TOTAL']
    df['BAD_RATE2']=df['BAD'].cumsum()/df['TOTAL'].cumsum()
    df['LIFT'] = df['BAD_RATE2']/df['BAD_RATE2'].iloc[-1]
    return df[['TOTAL','CUMULATIVE','GOOD','BAD','GOOD_CUM_RATE','BAD_CUM_RATE','BAD_RATE1','BAD_RATE2','LIFT']],cuts
 
def report_data_stat(sample_dats,y_col='y',data_group=None,weight_col=None):
    if data_group is None and weight_col is None:
        tmp1 = map(lambda a:a[y_col].value_counts(),sample_dats.values())
    else:
        tmp_group=[]
        if data_group is not None:
            tmp_group.extend(data_group)
        if weight_col is not None:
            tmp_group.append(weight_col)
        tmp1 = map(lambda a:a.groupby(tmp_group).count()[y_col],sample_dats.values())
    
        
    stat = pd.concat(tmp1,axis=1)
    stat.columns=list(sample_dats.keys())
    data_names=list(stat.columns)
    if weight_col is not None:
        stat.reset_index(inplace=True)
        for i in data_names:  
            stat['%s(weight)'%i] = (stat[i]*stat[weight_col]).apply(lambda a:np.int(np.around(a,0)))
        stat.set_index(tmp_group,inplace=True)
    return stat
    
def report_var_select(all_cols,model_cols,Ddel,user_save,report_col_sort,var_describe=None):
    tmp = pd.DataFrame(index=all_cols)
    tmp['是否入模'] = np.nan
    
    if user_save is not None:
        tmp.loc[tmp.index.isin(user_save),'是否入模']='****是[建模人员保留]****'
           
    for k,v in Ddel.items():
        if v[2] is not None:
            tmp.loc[tmp.index.isin(v[0]),'是否入模']='否[删除原因 = %s][阈值  = %s]'%(k,v[2])
        else:
            tmp.loc[tmp.index.isin(v[0]),'是否入模']='否[删除原因 = %s]'%(k)
        if v[1] is not None:
            v[1].name=k
            tmp = tmp.merge(v[1],left_index=True,right_index=True,how='left')
        elif k in report_col_sort:
            report_col_sort.remove(k)
            
    tmp.loc[model_cols,'是否入模'] = '****是****'        
    report_col_sort.append('是否入模')   
    if  var_describe is not None:
        return tmp[report_col_sort].merge(var_describe,left_index=True,right_index=True)
    else:
        return tmp[report_col_sort]
      
def report_card(card,var_describe=None):
    card = pd.concat(card)
    card = card.query('variable!="basepoints"')
    if var_describe is not None:
        return card[['variable','bin','points']].merge(var_describe,left_on='variable',right_index=True)
    else:
        return card[['variable','bin','points']]

def report_reg_clf(clf):
    tmp=pd.read_html(clf.summary().tables[1].as_html(), header=0, index_col=0)[0]
    tmp=tmp.reset_index()
    tmp=tmp[['index','coef','std err','z','P>|z|']].rename(columns={'index':'变量','coef':'Estimate','std err':'Standard Error','z':'Wald Chi-Square','P>|z|':'Pr > ChiSq'})
    tmp['变量'][0]='Intercept'
    return tmp

def report_vif(df,cols):
    return vif(df[cols])

def report_opt_bins(bins,var_describe=None):
    df_bins = pd.concat(bins) 
    df_bins =  df_bins[['variable','bin','count','count_distr','good','bad','badprob','woe','bin_iv','total_iv','breaks','is_special_values']] 
    if var_describe is not None:
        df_bins = df_bins.merge(var_describe,left_index=True,right_index = True)        
    return df_bins

#interval_cut_by如果只有一个，则按照每一层数据各切各的。如果有两个，则指定一个基准，所有都按照这个基础切
def report_perfermance(writer,dats,card,cols,y_col='y',weight_col=None,interval_cut_by=['train'],comp_interval_no=10,detail_interval_no=100,detail_head=5,show_lift=(1,5,10),reverse_between_score_prob=True):
        
    import copy
    dats = copy.deepcopy(dats)
    for name1,ds in dats.items():
        for name2,dt in ds.items():
            dt['score'] = sc.scorecard_ply(dt[cols], card)
           
    if len(interval_cut_by)==2:
        _,cuts1 =  lift(dats[interval_cut_by[0]][interval_cut_by[1]],score_col='score',weight_col=weight_col,n=comp_interval_no)
        _,cuts2 =  lift(dats[interval_cut_by[0]][interval_cut_by[1]],score_col='score',weight_col=weight_col,n=detail_interval_no)
        for name1,ds in dats.items():
            for name2,dt in ds.items():
                 dats[name1][name2]=(dt,cuts1,cuts2)
    elif len(interval_cut_by)==1:
        for name1,ds in dats.items():
            for name2,dt in ds.items():
                if name2 == interval_cut_by[0]:
                    _,cuts1 =  lift(dats[name1][interval_cut_by[0]],'score',y_col,weight_col,comp_interval_no)
                    _,cuts2 =  lift(dats[name1][interval_cut_by[0]],'score',y_col,weight_col,detail_interval_no)
                    for name2_1,dt2 in ds.items():
                        dats[name1][name2_1]=(dt2,cuts1,cuts2)
                    break
    
    
    columns=['SAMPLE','KS','AUC']
    for i in show_lift:
        columns.append('LIFT%d'%i)
    df_perf_summary=pd.DataFrame(columns=columns)
    row_width=5
    row_curr=0    
    for name1,ds in dats.items():
        for name2,dt in ds.items(): 
            for i in ['comp','detail']:
                tmp_n = comp_interval_no if i =='comp' else detail_interval_no
                tmp_cuts = dt[1] if i =='comp' else dt[2]
                tmp_lift,_ = lift(dt[0],'score',y_col,weight_col,tmp_n,tmp_cuts)
                tmp_lift.reset_index(inplace=True)
                tmp_lift.INTEVAL = tmp_lift.INTEVAL.apply(str)
                if i == 'detail':
                    detail_head_str='  前%d'%detail_head
                    y = dt[0][y_col]
                    score = dt[0]['score']
                    if weight_col is None:
                        w = None
                    else:
                        w = dt[0][weight_col]
                    ks = KS(y , score, w)
                    if reverse_between_score_prob:
                        auc = 1-AUC(y , score, w)
                    else:
                        auc = AUC(y , score, w)
                    tmp = ['%s  %s'%(name1,name2),ks,auc]
                    for j in show_lift:
                        if tmp_lift.shape[0] >= j:
                            tmp.append(tmp_lift.LIFT.iloc[j-1])
                        else:
                            tmp.append(np.nan)
                    df_perf_summary.loc[df_perf_summary.shape[0]]=tmp
                    tmp_lift=tmp_lift.head(detail_head)
                else:
                    detail_head_str=''
                tmp_lift.loc[tmp_lift.shape[0]]=['SUMMARY',tmp_lift.TOTAL.sum(),np.nan,tmp_lift.GOOD.sum(),tmp_lift.BAD.sum(),np.nan,np.nan,tmp_lift.BAD.sum()/tmp_lift.TOTAL.sum(),np.nan,np.nan]
                tmp_lift['SAMPLE'] = '%s  %s%s'%(name1,name2,detail_head_str)
                tmp_lift.set_index(['SAMPLE','INTEVAL'],inplace=True)

                row_curr = row_curr + row_width
                tmp_lift.to_excel(writer, sheet_name='05 模型性能',startcol=4,startrow=row_curr,float_format='%.4f')
                row_curr = row_curr + tmp_lift.shape[0]
               

    df_perf_summary.to_excel(writer, sheet_name='05 模型性能',startcol=20,startrow=10,float_format='%.4f',index=False)    
 
def gen_report(sample_datas,perfermance_datas,train_woe,clf,model_cols,card,prev_bins,bins,y_col = 'y',y_label={'good':0,'bad':1},weight_col=None,data_group_cols=None,var_sclect={},user_save_cols=[],var_sclect_cols_sort=[],interval_cut_by=['train'],comp_interval_no=10,detail_interval_no=100,detail_head=5,show_lift=(1,5,10),reverse_between_score_prob=True,filePath='report.xlsx'):
    r2_data_stat = report_data_stat(sample_datas,y_col,data_group_cols,weight_col)
    
    r3_var_all_cols = list(list(sample_datas.values())[0].columns)
    r3_var_all_cols.remove(y_col)
    if weight_col is not None:
        r3_var_all_cols.remove(weight_col)
    if data_group_cols is not None:
        for i in data_group_cols:
            r3_var_all_cols.remove(i)
    r3_var_sel = report_var_select(r3_var_all_cols,model_cols,var_sclect,user_save_cols,var_sclect_cols_sort)
    
    r4_card = report_card(card)
    r6_logit = report_reg_clf(clf)
    r7_VIF = report_vif(train_woe,model_cols)
    
    r8_freq_bin = report_opt_bins(prev_bins)
    r8_freq_bin_model = r8_freq_bin.loc[r8_freq_bin.variable.isin(model_cols)]
    r8_opt_bin = report_opt_bins(bins)
    r8_opt_bin_model = r8_opt_bin.loc[r8_opt_bin.variable.isin(model_cols)]
    
    r9_corr = train_woe[model_cols].corr()
    
    if filePath is not None:
        with pd.ExcelWriter(filePath) as writer:
            r2_data_stat.to_excel(writer, sheet_name='02 建模数据描述',float_format='%.4f')
            r3_var_sel.to_excel(writer, sheet_name='03 变量筛选',float_format='%.4f')
            r4_card.to_excel(writer, sheet_name='04 最终评分卡',index=False)
            report_perfermance(writer,perfermance_datas,card,model_cols,y_col,weight_col,interval_cut_by,comp_interval_no,detail_interval_no,detail_head,show_lift,reverse_between_score_prob)
            r6_logit.to_excel(writer, sheet_name='06 回归结果',index=False)
            r7_VIF.to_excel(writer, sheet_name='07 VIF',index=False)
            r8_freq_bin.to_excel(writer, sheet_name='08 单变量分析（等频预分箱）')
            r8_freq_bin_model.to_excel(writer, sheet_name='08 入模单变量分析（等频预分箱）')
            r8_opt_bin.to_excel(writer, sheet_name='08 单变量分析（最优分箱）')
            r8_opt_bin_model.to_excel(writer, sheet_name='08 入模单变量分析（最优分箱）')
            r9_corr.to_excel(writer, sheet_name='09 变量相关性分析')     
            
def gen_report2(sample_datas,train_data_name,perfermance_datas,train_woe,clf,model_cols,card,prev_bins,bins,y_col = 'y',y_label={'good':0,'bad':1},weight_col=None,data_group_cols=None,var_sclect={},user_save_cols=[],var_sclect_cols_sort=[],interval_cut_by=['train'],comp_interval_no=10,detail_interval_no=100,detail_head=5,show_lift=(1,5,10),reverse_between_score_prob=True,var_describe_file_path=None,filePath='report.xlsx'):
    def _around(inteval):
        if '[' in inteval and ',' in inteval and ')' in inteval:
            t1 = inteval[inteval.index('[')+1:inteval.index(',')]
            try:
                t1 = np.around(np.float(t1),2)
            except:
                t1=t1
            t1 = '[%s'%t1
            t2 = inteval[inteval.index(',')+1:inteval.index(')')]
            try:
                t2 = np.around(np.float(t2),4)
            except:
                t2=t2
            t2 = ', %s)'%t2
            inteval = t1+t2
        return inteval
    
    def _fix_bin(x):
        variable = x['variable']
        min_value=sample_datas[train_data_name][variable].min()
        x['bin'] = x['bin'].replace('-inf',str(min_value))
        x['bin'] = '%,%'.join(list(map(_around,x['bin'].split('%,%'))))
        return x
    
    def _fix_break(str_break):
        try:
            str_break = np.around(np.float(str_break),4)
        except:
            str_break=str_break
        return str(str_break)
    
    if var_describe_file_path is None:
        var_describe = None
    else:
        var_describe = pd.read_excel(var_describe_file_path,index_col=0)
    
    r2_data_stat = report_data_stat(sample_datas,y_col,data_group_cols,weight_col)
    
    r3_var_all_cols = list(list(sample_datas.values())[0].columns)
    r3_var_all_cols.remove(y_col)
    if weight_col is not None:
        r3_var_all_cols.remove(weight_col)
    if data_group_cols is not None:
        for i in data_group_cols:
            r3_var_all_cols.remove(i)
    r3_var_sel = report_var_select(r3_var_all_cols,model_cols,var_sclect,user_save_cols,var_sclect_cols_sort,var_describe)
    
    r4_card = report_card(card,var_describe)
    r4_card = r4_card.apply(_fix_bin,axis=1)
    r6_logit = report_reg_clf(clf)
    r7_VIF = report_vif(train_woe,model_cols)
    
    r8_freq_bin = report_opt_bins(prev_bins,var_describe=None)
    r8_freq_bin = r8_freq_bin.apply(_fix_bin,axis=1)
    r8_freq_bin['breaks'] = r8_freq_bin['breaks'].apply(_fix_break)
    r8_freq_bin['woe'] = r8_freq_bin['woe']*-1
    
    r8_freq_bin_model = r8_freq_bin.loc[r8_freq_bin.variable.isin(model_cols)]
    
    
    r8_opt_bin = report_opt_bins(bins,var_describe=None)
    r8_opt_bin = r8_opt_bin.apply(_fix_bin,axis=1)
    r8_opt_bin['breaks'] = r8_opt_bin['breaks'].apply(_fix_break)
    r8_opt_bin['woe'] = r8_opt_bin['woe']*-1
    
    
    r8_opt_bin_model = r8_opt_bin.loc[r8_opt_bin.variable.isin(model_cols)]
    
    r9_corr = train_woe[model_cols].corr()
    
    if filePath is not None:
        with pd.ExcelWriter(filePath) as writer:
            r2_data_stat.to_excel(writer, sheet_name='02 建模数据描述',float_format='%.4f')
            r3_var_sel.to_excel(writer, sheet_name='03 变量筛选',float_format='%.4f')
            r4_card.to_excel(writer, sheet_name='04 最终评分卡',index=False)
            report_perfermance(writer,perfermance_datas,card,model_cols,y_col,weight_col,interval_cut_by,comp_interval_no,detail_interval_no,detail_head,show_lift,reverse_between_score_prob)
            r6_logit.to_excel(writer, sheet_name='06 回归结果',index=False)
            r7_VIF.to_excel(writer, sheet_name='07 VIF',index=False)
            r8_freq_bin.to_excel(writer, sheet_name='08 单变量分析（等频预分箱）')
            r8_freq_bin_model.to_excel(writer, sheet_name='08 入模单变量分析（等频预分箱）')
            r8_opt_bin.to_excel(writer, sheet_name='08 单变量分析（最优分箱）')
            r8_opt_bin_model.to_excel(writer, sheet_name='08 入模单变量分析（最优分箱）')
            r9_corr.to_excel(writer, sheet_name='09 变量相关性分析')  