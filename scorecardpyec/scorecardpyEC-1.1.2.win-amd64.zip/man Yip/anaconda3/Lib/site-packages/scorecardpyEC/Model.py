# -*- coding: utf-8 -*-
"""
Created on Mon Dec 27 14:36:23 2021

@author: man Yip

1.读取数据
2.预分箱
3.分箱（单调） 
4.merge_special_values
5.按照分箱模板将非训练数据进行分箱（为了过滤特征）
6.woe转换
7.过滤特征
8.建模
9.调整模型
10.card转换
11.报表

特征过滤会依据配置在每个合适的阶段进行计算

"""

import configparser
import pandas as pd
import pickle
import sys
sys.path.append('./')
from Bin import ECBin
import copy
import numpy as np
from itertools import combinations
import os
import Filter
import scorecardpy as sc

class ModelFlow(): 
    
    def __init__(self,config_file,encoding='utf-8',start_stage=1,end_stage=10,user_model_cols=None):
        #running instance
        self.start_stage = start_stage
        self.end_stage = end_stage
        self.not_feature_cols=[]
        self.user_model_cols=user_model_cols
        config = configparser.ConfigParser()
        config.read(config_file,encoding=encoding)
        import Config
        Config.project_config(self,config)
        Config.data_config(self,config)
        for i in [self.y,self.sample_weight_col]:
            if i is not None:
                self.not_feature_cols.append(i)
        if self.data_group_cols is not None:
            self.not_feature_cols.extend(self.data_group_cols)
        Config.bins_config(self,config)
        Config.filter_x_config(self,config)
        Config.model_config(self,config)
        for i in [self.fit_weight_col,self.measure_weight_col]:
            if i is not None:
                self.not_feature_cols.append(i)
        Config.card_config(self,config)
        Config.report_config(self,config)
        
    def do_load_datas(self):
        do_sort=1
        
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_datas.pkl'%(self.work_space,do_sort),'rb') as f:
                self.datas = pickle.load(f)
            self.saved_X_cols=list(self.datas[self.train_data_name].columns)
            self.saved_X_cols=[i for i in self.saved_X_cols if i not in self.not_feature_cols]
            return
        
        print('The running stage is %d[do_load_datas]............'%do_sort)
        self.datas={}
        for f in os.listdir(self.data_file_path):
            ind = f.rfind('.')
            suf = f[ind+1:]
            name = f[:ind]
            file = '%s/%s'%(self.data_file_path,f)
            
            if suf=='xlsx':
                self.datas[name] = pd.read_excel(file,index_col=0)
            elif suf=='csv':
                self.datas[name] = pd.read_csv(file,index_col=0)
            elif suf=='pkl':
                with open(file,'rb') as f:
                    self.datas[name] = pickle.load(f)
        for k,dat in self.datas.items():
            dat[self.y] = pd.concat([pd.Series(0,dat[self.y].loc[dat[self.y]==self.y_label['good']].index),pd.Series(1,dat[self.y].loc[dat[self.y]==self.y_label['bad']].index)]).loc[dat.index]
        with open('%s/%d_datas.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.datas,f) 
        self.saved_X_cols=list(self.datas[self.train_data_name].columns)
        self.saved_X_cols=[i for i in self.saved_X_cols if i not in self.not_feature_cols]

                                                  
    def do_prev_train_bins(self):
        do_sort=2
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_prev_train_bins.pkl'%(self.work_space,do_sort),'rb') as f:
                self.prev_bins = pickle.load(f)
            return
        print('The running stage is %d[do_prev_train_bins]............'%do_sort)
        cols=[self.y]
        if self.sample_weight_col is not None:
            cols.append(self.sample_weight_col)
        cols.extend(self.saved_X_cols)
        dat = self.datas[self.train_data_name][cols]
        
        self.prev_bins = ECBin.woebin_mp(dat,y=self.y, stop_limit=0, count_distr_limit=0.01,bin_num_limit=100,no_cores = self.no_cores,weight=self.sample_weight_col,step=self.running_step)
        with open('%s/%d_prev_train_bins.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.prev_bins,f) 
        pd.concat(self.prev_bins).to_excel('%s/%d_prev_train_bins.xlsx'%(self.work_space,do_sort))
        
               
    def do_train_bins(self):
        do_sort=3
         
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_train_bins.pkl'%(self.work_space,do_sort),'rb') as f:
                self.train_bins = pickle.load(f)
            return
        print('The running stage is %d[do_train_bins]....................'%do_sort)
        cols=[self.y]
        if self.sample_weight_col is not None:
            cols.append(self.sample_weight_col)
        cols.extend(self.saved_X_cols)
        dat = self.datas[self.train_data_name][cols]
        if self.is_monotonic:
            self.train_bins = ECBin.make_monotonic_bins_mp(dat,y=self.y,breaks_list = self.breaks_list,special_values = self.special_values,stop_limit= self.stop_limit,bin_num_limit = self.bin_num_limit,no_cores = self.no_cores,method = self.method,weight=self.sample_weight_col,step=self.running_step,min_distr_limit=self.min_distr_limit,max_distr_limit=self.max_distr_limit,distr_step=self.distr_step,**self.kw_bins_args)[0]
        else:
            self.train_bins = ECBin.woebin_mp(dat,y=self.y,breaks_list = self.breaks_list,special_values = self.special_values,stop_limit= self.stop_limit,count_distr_limit=self.count_distr_limit,bin_num_limit = self.bin_num_limit,no_cores = self.no_cores,method = self.method,weight=self.sample_weight_col,step=self.running_step,**self.kw_bins_args)
        with open('%s/%d_train_bins.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.train_bins,f) 
        pd.concat(self.train_bins).to_excel('%s/%d_train_bins.xlsx'%(self.work_space,do_sort))
        
    def do_train_merge_bins(self):
        do_sort=4
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_train_final_bins.pkl'%(self.work_space,do_sort),'rb') as f:
                self.train_final_bins = pickle.load(f)
            return
        print('The running stage is %d[do_train_final_bins]...................'%do_sort)
        self.train_final_bins = copy.deepcopy(self.train_bins)
        if not self.is_merge_special_values:
            return
        
        if self.merge_missing_differ_treat=='off':
            ECBin.merge_special_values(self.train_final_bins,special_value_count_distr_limit_default=self.merge_special_count_distr_limit)   
        else:    
            ECBin.merge_missing(self.train_final_bins,missing_count_distr_limit_default=self.merge_special_count_distr_limit,rule_default=self.merge_missing_differ_treat)
            ECBin.merge_special_values(self.train_final_bins,special_value_count_distr_limit_default=self.merge_special_count_distr_limit)   
        with open('%s/%d_train_final_bins.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.train_final_bins,f) 
        pd.concat(self.train_final_bins).to_excel('%s/%d_train_final_bins.xlsx'%(self.work_space,do_sort))
        
    def do_trans_bin(self):
        do_sort=5
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_final_bins_trans.pkl'%(self.work_space,do_sort),'rb') as f:
                self.final_bins_trans = pickle.load(f)
            return
        print('The running stage is %d[do_trans_bin]...................'%do_sort)
        self.final_bins_trans={self.train_data_name:self.train_final_bins}
        for k,v in self.datas.items():
            if k !=self.train_data_name:
                tmp = ECBin.trans_data_to_woebin(v,self.train_final_bins,y=self.y,weight=self.sample_weight_col)
                pd.concat(tmp).to_excel('%s/%d_final_bins_trans_%s.xlsx'%(self.work_space,do_sort,k))
                self.final_bins_trans[k]=tmp
                
        with open('%s/%d_final_bins_trans.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.final_bins_trans,f) 

    def do_trans_woe(self):
        do_sort=6
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_trans_woe.pkl'%(self.work_space,do_sort),'rb') as f:
                self.woe_datas = pickle.load(f)
            return
        print('The running stage is %d[do_trans_woe]...................'%do_sort)
        tmp_datas={}
        for k,v in self.datas.items():
            tmp_datas[k] = v[self.saved_X_cols]
        self.woe_datas = ECBin.woevalue_mp(tmp_datas,self.train_final_bins,step=self.running_step,no_cores=self.no_cores)
        with open('%s/%d_trans_woe.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.woe_datas,f)
        
    def do_filter_x(self):
        do_sort=7
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_filtered_cols.pkl'%(self.work_space,do_sort),'rb') as f:
                self.filtered_cols = pickle.load(f)
            for k,v in self.filtered_cols.items():
                for i in v[0]:
                    if i in self.saved_X_cols:
                        if (self.user_save is None) or (i not in self.user_save):
                            self.saved_X_cols.remove(i)
            return
        print('The running stage is %d[do_filter_x]...................'%do_sort)
        self.filtered_cols={}
        for i in self.x_filter:
            filter_item = i.split(':')
            print('##The current filter is %s....'%filter_item[0])
            if len(filter_item)==2:
                eval('Filter.%s(self,%s)'%(filter_item[0],filter_item[1]))
            else:
                eval('Filter.%s(self)'%filter_item[0])
        Filter.user_del(self)        
        with open('%s/%d_filtered_cols.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.filtered_cols,f)
        tmp = pd.concat([pd.Series(v[0],name=k) for k,v in self.filtered_cols.items()],axis=1)
        tmp.to_excel('%s/%d_filtered_cols.xlsx'%(self.work_space,do_sort))
                
    def do_model(self):
        do_sort=8
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_model.pkl'%(self.work_space,do_sort),'rb') as f:
                self.lr_result = pickle.load(f)
                del_cols = list(self.lr_result[2].keys())
                self.filtered_cols['逐步回归删除'] = (del_cols,None,None)
                for i in del_cols:
                    if i in self.saved_X_cols:
                        self.saved_X_cols.remove(i)
            return
        print('The running stage is %d[do_model]...................'%do_sort)
        import MultiProcessMStepRegression as mpmr
        
        y = self.datas[self.train_data_name][self.y]
        X = self.woe_datas[self.train_data_name][self.saved_X_cols].loc[y.index]
        
        fit_weight = None
        if self.fit_weight_col is not None:
            fit_weight = self.datas[self.train_data_name][self.fit_weight_col].loc[y.index]
        
        measure_weight = None
        if self.measure_data_name is None:
            measure_X = None
            measure_y = None
            if self.measure_weight_col is not None:
                measure_weight = self.datas[self.train_data_name][self.measure_weight_col].loc[y.index]
        else:
            measure_y = self.datas[self.measure_data_name][self.y]
            measure_X = self.woe_datas[self.measure_data_name][self.saved_X_cols].loc[measure_y.index]
            if self.measure_weight_col is not None:
                measure_weight = self.datas[self.measure_data_name][self.measure_weight_col].loc[measure_y.index]
        
        lr  =  mpmr.LogisticReg(X,y,fit_weight=fit_weight,measure=self.measure_index,measure_weight=measure_weight,measure_frac=self.measure_frac,measure_X=measure_X,measure_y=measure_y,kw_measure_args=self.kw_measure_args,max_pvalue_limit=self.max_pvalue_limit,max_vif_limit=self.max_vif_limit,max_corr_limit=self.max_corr_limit,coef_sign=self.coef_sign,iter_num=self.iter_num,kw_algorithm_class_args=self.kw_algorithm_class_args,n_core=self.no_cores,logger_file_CH='%s/%d_logit_ch.log'%(self.work_space,do_sort),logger_file_EN='%s/%d_logit_en.log'%(self.work_space,do_sort))
        self.lr_result = lr.fit()
        with open('%s/%d_model.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.lr_result,f)
        
        del_cols = list(self.lr_result[2].keys())
        self.filtered_cols['逐步回归删除'] = (del_cols,None,None)
        for i in del_cols:
            if i in self.saved_X_cols:
                self.saved_X_cols.remove(i)
                
    def do_user_model(self):
        if self.user_model_cols is None:
            return
        
        do_sort=9
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_user_model.pkl'%(self.work_space,do_sort),'rb') as f:
                self.lr_user = pickle.load(f)
            del_cols = list(set(self.saved_X_cols) - set(self.user_model_cols))
            self.filtered_cols['没有进入到指定入模变量'] = (del_cols,None,None)
            for i in del_cols:
                if i in self.saved_X_cols:
                    self.saved_X_cols.remove(i) 
            return
        print('The running stage is %d[do_user_model]...................'%do_sort)
        y = self.datas[self.train_data_name][self.y]
        X = self.woe_datas[self.train_data_name].loc[y.index,self.user_model_cols]
        from statsmodels.genmod.generalized_linear_model import GLM
        from statsmodels.genmod.families import Binomial
        from statsmodels.genmod.families.links import logit
        import statsmodels.api as sm
        
        fit_weight = None
        if self.fit_weight_col is not None:
            fit_weight = self.datas[self.train_data_name][self.fit_weight_col].loc[y.index]

        if fit_weight is None:
            if self.kw_algorithm_class_args is not None:
                glm = GLM(y,sm.add_constant(X),family = Binomial(link=logit),**self.kw_algorithm_class_args)
            else:
                glm = GLM(y,sm.add_constant(X),family = Binomial(link=logit))
        else:
            if self.kw_algorithm_class_args is not None:
                glm = GLM(y,sm.add_constant(X),family = Binomial(link=logit),freq_weights = fit_weight,**self.kw_algorithm_class_args)
            else:
                glm = GLM(y,sm.add_constant(X),family = Binomial(link=logit),freq_weights = fit_weight)         
        self.lr_user = glm.fit()      
        self.lr_user.intercept_=[self.lr_user.params.const]
        self.lr_user.coef_=[self.lr_user.params[1:]]
        
        with open('%s/%d_user_model.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.lr_user,f)
        
        del_cols = list(set(self.saved_X_cols) - set(self.user_model_cols))
        self.filtered_cols['没有进入到指定入模变量'] = (del_cols,None,None)
        for i in del_cols:
            if i in self.saved_X_cols:
                self.saved_X_cols.remove(i)  
                
                
    def do_card(self):
        do_sort=10
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            with open('%s/%d_card.pkl'%(self.work_space,do_sort),'rb') as f:
                self.card = pickle.load(f)
            return
        print('The running stage is %d[do_card]...................'%do_sort)
        if self.odds0 is None:
            tmp = self.datas[self.train_data_name][self.y]
            self.odds0 = tmp.loc[tmp==1].shape[0]/tmp.loc[tmp==0].shape[0]
        if self.user_model_cols is None:
            lr = self.lr_result[1]
            in_model_cols = self.lr_result[0]
        else:
            lr = self.lr_user
            in_model_cols = self.user_model_cols
        self.card = sc.scorecard(self.train_final_bins,lr,in_model_cols,self.points0,self.odds0,self.pdo,self.basepoints_eq0) 
        with open('%s/%d_card.pkl'%(self.work_space,do_sort),'wb') as f:
            pickle.dump(self.card,f)
        
    def do_report(self):
        do_sort=11
        if self.end_stage < do_sort:
            return
        if self.start_stage > do_sort:
            return
               
               
        from Report import gen_report,gen_report2
        print('The running stage is %d[do_report]...................'%do_sort)
        
        self.perf_datas = {'1.MODEL':self.datas}
        
        if self.perf_pivot_table_data_file_path is not None:
            for fold in os.listdir(self.perf_pivot_table_data_file_path):
                tmp={}
                for file in os.listdir('%s/%s'%(self.perf_pivot_table_data_file_path,fold)):
                    ind = file.rfind('.')
                    suf = file[ind+1:]
                    name = file[:ind]
                    file = '%s/%s/%s'%(self.perf_pivot_table_data_file_path,fold,file)
                    
                    if suf=='xlsx':
                        tmp[name] = pd.read_excel(file,index_col=0)
                    elif suf=='csv':
                        tmp[name] = pd.read_csv(file,index_col=0)
                    elif suf=='pkl':
                        with open(file,'rb') as f:
                            tmp[name] = pickle.load(f)
                self.perf_datas[fold]=tmp
        
        if self.user_model_cols is None:
            lr = self.lr_result[1]
            in_model_cols = self.lr_result[0]
        else:
            lr = self.lr_user
            in_model_cols = self.user_model_cols
        # gen_report(self.datas,self.perf_datas,self.woe_datas[self.train_data_name],lr,in_model_cols,self.card,self.prev_bins,self.train_final_bins,self.y,{'good':0,'bad':1},self.sample_weight_col,self.data_group_cols,self.filtered_cols,self.user_save,[i.split(':')[0] for i in self.x_filter],self.interval_cut_by,self.table1_interval_no ,self.table2_interval_no,self.table2_head,self.show_lift,self.reverse_between_score_prob,'%s/%d_%s.xlsx'%(self.work_space,do_sort,self.report_name))
        gen_report2(self.datas,self.train_data_name,self.perf_datas,self.woe_datas[self.train_data_name],lr,in_model_cols,self.card,self.prev_bins,self.train_final_bins,self.y,{'good':0,'bad':1},self.sample_weight_col,self.data_group_cols,self.filtered_cols,self.user_save,[i.split(':')[0] for i in self.x_filter],self.interval_cut_by,self.table1_interval_no ,self.table2_interval_no,self.table2_head,self.show_lift,self.reverse_between_score_prob,self.var_describe_file_path,'%s/%d_%s.xlsx'%(self.work_space,do_sort,self.report_name))

                
    def start(self):
        self.do_load_datas()
        self.do_prev_train_bins()
        self.do_train_bins()
        self.do_train_merge_bins()
        self.do_trans_bin()
        self.do_trans_woe()
        self.do_filter_x()
        self.do_model()
        self.do_user_model()
        self.do_card()
        self.do_report()        
        
        
        
    def show_config(self):
        print('#####################[PROJECT CONFIG]####################')
        print('model_name:',self.model_name)
        print('work_space:',self.work_space)
        print('running_step:',self.running_step)
        
        print('#[DATA CONFIG]')
        print('data_file_path:',self.data_file_path)
        print('train_data_name:',self.train_data_name)
        print('y:',self.y)
        print('y_label:',self.y_label)
        print('sample_weight_col:',self.sample_weight_col)
              
        print('#####################[BINS CONFIG]####################')
        print('is_monotonic:',self.is_monotonic)
        print('breaks_list:',self.breaks_list)
        print('special_values:',self.special_values)
        print('stop_limit:',self.stop_limit)
        print('bin_num_limit:',self.bin_num_limit)  
        print('count_distr_limit:',self.count_distr_limit)
        print('no_cores:',self.no_cores)
        print('method:',self.method)
        print('min_distr_limit:',self.min_distr_limit)
        print('max_distr_limit:',self.max_distr_limit)
        print('distr_step:',self.distr_step)
        print('is_merge_special_values:',self.is_merge_special_values)
        print('merge_missing_differ_treat:',self.merge_missing_differ_treat) 
        print('merge_special_count_distr_limit:',self.kw_bins_args)
        print('kw_bins_args:',self.kw_bins_args)  
        
        print('##############[FILTER_X CONFIG]####################')
        print(self.x_filter)
        print(self.user_del)
        
        print('#####################[MODEL CONFIG]####################')
        print(self.fit_weight_col)
        print(self.measure_index)
        print(self.measure_weight_col)
        print(self.measure_frac)
        print(self.measure_data_name)
        print(self.kw_measure_args)
        print(self.max_pvalue_limit)
        print(self.max_vif_limit)
        print(self.max_corr_limit)
        print(self.coef_sign)
        print(self.iter_num)
        print(self.kw_algorithm_class_args)
            
        print('#####################[REPORT CONFIG]####################')
        print(self.report_name)